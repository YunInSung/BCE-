loss0 = 1.0535636507329975
loss_Z-0 : 0.8572138025824204

loss_Z-1 : 0.4489174290273932

loss_Z-2 : 0.2555677955738371

loss_Z-3 : 0.17868836248657477

loss_Z-4 : 0.12579699828990307

loss_Z-5 : 0.09053190177107928

loss_Z-6 : 0.06590446965906945

loss_Z-7 : 0.04860902911635707

loss_Z-8 : 0.0364496689229624

loss_Z-9 : 0.02449448354230137

loss_Z-10 : 0.018283365755285004

loss_Z-11 : 0.013749569658639629

loss_Z-12 : 0.010347933222291335

loss_Z-13 : 0.007784097521634361

loss_Z-14 : 0.0058522503769569125

loss_Z-15 : 0.0043796783273729704

loss_Z-16 : 0.003249024694296152

loss_Z-17 : 0.0023818531630319436

loss_Z-18 : 0.00170291617949655

loss_Z-19 : 0.00119985681675992

loss_Z-20 : 0.0008303506786442163

loss_Z-21 : 0.0005678836376450726

나의 코드 실행 시간: 1.0505 초
loss : 0.0005678836376450726
Epoch 100, Loss: 0.0186
Adam 학습 코드 실행 시간: 0.2239 초
학습 완료
Validation Loss: 0.0267
Validatio loss in my model : 0.0018405780724163599
data : 5000
loss0 = 0.8406656896793157
loss_Z-0 : 0.4644271911900616

loss_Z-1 : 0.2534246597692067

loss_Z-2 : 0.17936190123891974

loss_Z-3 : 0.1278325557212204

loss_Z-4 : 0.09369868250361209

loss_Z-5 : 0.06449360263783006

loss_Z-6 : 0.04649357295989567

loss_Z-7 : 0.033612153370479896

loss_Z-8 : 0.023998333526767758

loss_Z-9 : 0.016339763742226322

loss_Z-10 : 0.011205295082672815

loss_Z-11 : 0.007415015052118835

loss_Z-12 : 0.004884281851856867

loss_Z-13 : 0.0031729897530316247

loss_Z-14 : 0.0020682655047600056

loss_Z-15 : 0.0011399660324413737

loss_Z-16 : 0.0006954985401594894

loss_Z-17 : 0.00041551085323948217

나의 코드 실행 시간: 0.8076 초
loss : 0.00041551085323948217
Epoch 100, Loss: 0.0161
Adam 학습 코드 실행 시간: 0.1700 초
학습 완료
Validation Loss: 0.0220
Validatio loss in my model : 0.0024264724959238244
data : 5000
loss0 = 0.9163956279698994
loss_Z-0 : 0.40541156396977884

loss_Z-1 : 0.312483329642842

loss_Z-2 : 0.2208841006212111

loss_Z-3 : 0.222935029499748

it : 3 - learn : 0.037500000000000006
loss_Z-4 : 0.20453675510456804

loss_Z-5 : 9.671709713055886

it : 5 - learn : 0.028125000000000004
loss_Z-6 : 9.656083975629072

it : 6 - learn : 0.02109375
loss_Z-7 : 9.649126275545175

it : 7 - learn : 0.015820312500000003
loss_Z-8 : 9.643868564950974

it : 8 - learn : 0.011865234375000002
loss_Z-9 : 9.635507549677993

it : 9 - learn : 0.00889892578125
loss_Z-10 : 9.621897502671874

it : 10 - learn : 0.0066741943359375005
loss_Z-11 : 9.596939197700605

it : 11 - learn : 0.005005645751953125
loss_Z-12 : 9.548449946798236

it : 12 - learn : 0.003754234313964844
loss_Z-13 : 9.442890529620053

it : 13 - learn : 0.002815675735473633
loss_Z-14 : 9.234051513167072

it : 14 - learn : 0.0021117568016052247
loss_Z-15 : 8.859360139462272

it : 15 - learn : 0.0015838176012039186
loss_Z-16 : 8.010755137107973

it : 16 - learn : 0.001187863200902939
loss_Z-17 : 6.243273959432765

it : 17 - learn : 0.0008908974006772042
loss_Z-18 : 3.6349410615327433

it : 18 - learn : 0.0006681730505079032
loss_Z-19 : 1.7440222206685332

it : 19 - learn : 0.0005011297878809274
loss_Z-20 : 0.8146525885222089

it : 20 - learn : 0.0003758473409106955
loss_Z-21 : 0.4289002472327651

it : 21 - learn : 0.00028188550568302166
loss_Z-22 : 0.2870439800794712

it : 22 - learn : 0.00021141412926226625
loss_Z-23 : 0.23607527808719256

it : 23 - learn : 0.00015856059694669967
loss_Z-24 : 0.2167708153957828

it : 24 - learn : 0.00011892044771002475
loss_Z-25 : 0.20891698693177047

it : 25 - learn : 8.919033578251856e-05
loss_Z-26 : 0.20558511364917675

it : 26 - learn : 6.689275183688892e-05
loss_Z-27 : 0.20420635972766232

loss_Z-28 : 0.2040987057031531

loss_Z-29 : 0.20399110397043854

loss_Z-30 : 0.203883566049151

loss_Z-31 : 0.20377607898448963

loss_Z-32 : 0.20366866234669093

loss_Z-33 : 0.20356130465858702

loss_Z-34 : 0.20345400969050542

loss_Z-35 : 0.20334677265456563

loss_Z-36 : 0.20323959678572465

loss_Z-37 : 0.20313248155621322

loss_Z-38 : 0.20298799367179338

loss_Z-39 : 0.20279312636403693

loss_Z-40 : 0.2025303680815205

loss_Z-41 : 0.20217649828977372

loss_Z-42 : 0.20170017046232203

loss_Z-43 : 0.20105962735456911

loss_Z-44 : 0.2001997746849012

loss_Z-45 : 0.19904872433513948

loss_Z-46 : 0.19751518795914835

loss_Z-47 : 0.19548946124481492

loss_Z-48 : 0.19287469320433417

loss_Z-49 : 0.19065542119660792

loss_Z-50 : 0.18602373154348692

loss_Z-51 : 0.1816307188977214

loss_Z-52 : 0.17307400212963425

loss_Z-53 : 0.1629192060083548

loss_Z-54 : 0.15066240505135187

loss_Z-55 : 0.1384098853618129

loss_Z-56 : 0.1257167845279529

loss_Z-57 : 0.11575938758764559

loss_Z-58 : 0.10675197513815483

loss_Z-59 : 0.09856724235447116

loss_Z-60 : 0.09110892955615489

loss_Z-61 : 0.08430121115254896

loss_Z-62 : 0.07807573683601872

loss_Z-63 : 0.07236037103199601

loss_Z-64 : 0.06711486145411537

loss_Z-65 : 0.06229004144459343

loss_Z-66 : 0.057844613102063944

loss_Z-67 : 0.05373465924762175

loss_Z-68 : 0.049928644405130396

loss_Z-69 : 0.046400120053789316

loss_Z-70 : 0.04311772430400326

loss_Z-71 : 0.04006640828720266

loss_Z-72 : 0.03723060150736427

loss_Z-73 : 0.034599104584060646

loss_Z-74 : 0.032155828522365745

나의 코드 실행 시간: 3.3567 초
loss : 0.032155828522365745
Epoch 100, Loss: 0.0197
Adam 학습 코드 실행 시간: 0.1627 초
학습 완료
Validation Loss: 0.0239
Validatio loss in my model : 0.03321682617116173
data : 5000
loss0 = 1.0903074338363752
loss_Z-0 : 0.32700246106544456

loss_Z-1 : 0.21189414194544487

loss_Z-2 : 0.14809889804500115

loss_Z-3 : 0.1049258430632045

loss_Z-4 : 0.07480493882751227

loss_Z-5 : 0.054014989386265824

loss_Z-6 : 0.03977373615544364

loss_Z-7 : 0.02252885453339405

loss_Z-8 : 0.012211757223691475

loss_Z-9 : 0.008596395953639861

loss_Z-10 : 0.006279719731637884

loss_Z-11 : 0.004621085868200497

loss_Z-12 : 0.00344232296647714

loss_Z-13 : 0.002452024749031599

loss_Z-14 : 0.0016711113464483677

loss_Z-15 : 0.0011231893266726153

loss_Z-16 : 0.0007500723862665316

loss_Z-17 : 0.0004721409465548162

나의 코드 실행 시간: 0.8623 초
loss : 0.0004721409465548162
Epoch 100, Loss: 0.0249
Adam 학습 코드 실행 시간: 0.1637 초
학습 완료
Validation Loss: 0.0298
Validatio loss in my model : 0.001957295673674664
data : 5000
loss0 = 1.0647965804455368
loss_Z-0 : 0.3674826526594926

loss_Z-1 : 0.24779632863361786

loss_Z-2 : 0.16954979602465584

loss_Z-3 : 0.11829408639535047

loss_Z-4 : 0.08334355453549394

loss_Z-5 : 0.05888692462627331

loss_Z-6 : 0.04160655366415376

loss_Z-7 : 0.029359278284201776

loss_Z-8 : 0.020663737123987797

loss_Z-9 : 0.014542048325238607

loss_Z-10 : 0.010194143692338105

loss_Z-11 : 0.007104665377410828

loss_Z-12 : 0.00494036862256383

loss_Z-13 : 0.0034121722564442493

loss_Z-14 : 0.0023313654036530595

loss_Z-15 : 0.0017012059073376903

loss_Z-16 : 0.0011205264330330668

loss_Z-17 : 0.0007140762659842363

loss_Z-18 : 0.00044244024604831605

나의 코드 실행 시간: 0.8770 초
loss : 0.00044244024604831605
Epoch 100, Loss: 0.0228
Adam 학습 코드 실행 시간: 0.1793 초
학습 완료
Validation Loss: 0.0287
Validatio loss in my model : 0.0017226074645364663
data : 5000
loss0 = 0.8458347119021251
loss_Z-0 : 0.3985308843224411

loss_Z-1 : 0.26291423669931846

loss_Z-2 : 0.18309315936044027

loss_Z-3 : 0.1303196935327984

loss_Z-4 : 0.09332938175789716

loss_Z-5 : 0.06740794759379551

loss_Z-6 : 0.048500046131877514

loss_Z-7 : 0.035114656296874415

loss_Z-8 : 0.025814801839900765

loss_Z-9 : 0.017461896052479785

loss_Z-10 : 0.012284498044363386

loss_Z-11 : 0.008528685978898118

loss_Z-12 : 0.0059639977291131175

loss_Z-13 : 0.00417858366112877

loss_Z-14 : 0.0028893848749729097

loss_Z-15 : 0.0019868022887536397

loss_Z-16 : 0.0012599625241526483

loss_Z-17 : 0.0007875595785159881

loss_Z-18 : 0.0004853769908871415

나의 코드 실행 시간: 0.8682 초
loss : 0.0004853769908871415
Epoch 100, Loss: 0.0175
Adam 학습 코드 실행 시간: 0.1756 초
학습 완료
Validation Loss: 0.0217
Validatio loss in my model : 0.0018576823411287058
data : 5000
loss0 = 1.3870398076161834
loss_Z-0 : 0.3533325528883411

loss_Z-1 : 1.5864165391145113

it : 1 - learn : 0.037500000000000006
loss_Z-2 : 0.7997561828754668

it : 2 - learn : 0.028125000000000004
loss_Z-3 : 0.4887761693064767

it : 3 - learn : 0.02109375
loss_Z-4 : 0.38809460422683323

it : 4 - learn : 0.015820312500000003
loss_Z-5 : 0.35406775477392083

it : 5 - learn : 0.011865234375000002
loss_Z-6 : 0.34173604014082665

loss_Z-7 : 0.30413428598842657

loss_Z-8 : 0.2735044693185237

loss_Z-9 : 0.24769898215051403

loss_Z-10 : 0.22394706664383965

loss_Z-11 : 0.2045127018821698

loss_Z-12 : 0.18738505209071685

loss_Z-13 : 0.17225140178588605

loss_Z-14 : 0.1588577051121557

loss_Z-15 : 0.1450863286447805

loss_Z-16 : 0.1338950769477954

loss_Z-17 : 0.12368191646836794

loss_Z-18 : 0.11439467805777677

loss_Z-19 : 0.10616190599930207

loss_Z-20 : 0.09657804957751041

loss_Z-21 : 0.08947815704974862

loss_Z-22 : 0.08297108897933894

loss_Z-23 : 0.07696552074792866

loss_Z-24 : 0.07121125712426378

loss_Z-25 : 0.06585587430364476

loss_Z-26 : 0.0612240825269131

loss_Z-27 : 0.047575256019681544

loss_Z-28 : 0.030132926539197344

loss_Z-29 : 0.030121804255421613

loss_Z-30 : 0.026359529041815176

loss_Z-31 : 0.023521309921638006

loss_Z-32 : 0.021030606805740693

loss_Z-33 : 0.019013645772051557

loss_Z-34 : 0.017281742472454592

loss_Z-35 : 0.01576171753223046

loss_Z-36 : 0.014409655305421458

loss_Z-37 : 0.013211554656020775

loss_Z-38 : 0.012140114904441593

loss_Z-39 : 0.011178496736900826

loss_Z-40 : 0.010310830069970581

loss_Z-41 : 0.009521869644764256

loss_Z-42 : 0.008798767070641127

loss_Z-43 : 0.008137194192617705

loss_Z-44 : 0.007530717169088555

loss_Z-45 : 0.006971328314105333

loss_Z-46 : 0.006449365028043897

loss_Z-47 : 0.0059592717761447105

loss_Z-48 : 0.005508173529618692

loss_Z-49 : 0.005094345285148445

loss_Z-50 : 0.004713710525832721

loss_Z-51 : 0.004360692301105108

loss_Z-52 : 0.004033774671042218

loss_Z-53 : 0.0037275761213354827

loss_Z-54 : 0.0034401864067055642

loss_Z-55 : 0.0031776650580815427

loss_Z-56 : 0.00294239488073934

loss_Z-57 : 0.0021646277803883764

loss_Z-58 : 0.0016659697451317616

loss_Z-59 : 0.004568251130538385

it : 59 - learn : 0.00889892578125
loss_Z-60 : 0.00328833259847405

it : 60 - learn : 0.0066741943359375005
loss_Z-61 : 0.002494720152714524

it : 61 - learn : 0.005005645751953125
loss_Z-62 : 0.0020515229731347495

it : 62 - learn : 0.003754234313964844
loss_Z-63 : 0.0018400776240432475

it : 63 - learn : 0.002815675735473633
loss_Z-64 : 0.0017481747846812155

it : 64 - learn : 0.0021117568016052247
loss_Z-65 : 0.001705964137794561

it : 65 - learn : 0.0015838176012039186
loss_Z-66 : 0.0016852610630198272

it : 66 - learn : 0.001187863200902939
loss_Z-67 : 0.0016742047041780667

it : 67 - learn : 0.0008908974006772042
loss_Z-68 : 0.0016682162815234026

it : 68 - learn : 0.0006681730505079032
loss_Z-69 : 0.0016655570263501012

loss_Z-70 : 0.0016547059843586972

loss_Z-71 : 0.0016424128330602135

loss_Z-72 : 0.0016315640632775256

loss_Z-73 : 0.0016207887243359514

loss_Z-74 : 0.0016101193244699623

나의 코드 실행 시간: 3.5671 초
loss : 0.0016101193244699623
Epoch 100, Loss: 0.0234
Adam 학습 코드 실행 시간: 0.1755 초
학습 완료
Validation Loss: 0.0322
Validatio loss in my model : 0.005868380539332527
data : 5000
loss0 = 1.0741847500680926
loss_Z-0 : 0.5754106586403033

loss_Z-1 : 0.2660862383576301

loss_Z-2 : 0.18320171490304493

loss_Z-3 : 0.13215133280643723

loss_Z-4 : 0.09452023283985118

loss_Z-5 : 0.06735634680074279

loss_Z-6 : 0.04909247498194229

loss_Z-7 : 0.036040795427476464

loss_Z-8 : 0.026661213959252767

loss_Z-9 : 0.022022214313059514

loss_Z-10 : 0.01612828778145191

loss_Z-11 : 0.012490722518332565

loss_Z-12 : 0.008783499397674834

loss_Z-13 : 0.00786859924252763

loss_Z-14 : 0.023647330309078625

it : 14 - learn : 0.037500000000000006
loss_Z-15 : 0.0061840017291868625

loss_Z-16 : 0.004514074819284585

loss_Z-17 : 0.00332571913149388

loss_Z-18 : 0.0021889011953188987

loss_Z-19 : 0.0015538252800368789

loss_Z-20 : 0.0011198469794266505

loss_Z-21 : 0.000798626709677815

loss_Z-22 : 0.0005680828729174006

나의 코드 실행 시간: 1.0730 초
loss : 0.0005680828729174006
Epoch 100, Loss: 0.0307
Adam 학습 코드 실행 시간: 0.1638 초
학습 완료
Validation Loss: 0.0347
Validatio loss in my model : 0.0020052852801771765
data : 5000
loss0 = 0.9584019972943694
loss_Z-0 : 1.8352757433641251

it : 0 - learn : 0.037500000000000006
loss_Z-1 : 0.9738372060967943

it : 1 - learn : 0.028125000000000004
loss_Z-2 : 0.5281052393574102

loss_Z-3 : 0.29129163826324367

loss_Z-4 : 0.22365187053972926

loss_Z-5 : 0.1767376196460574

loss_Z-6 : 0.1413724575289628

loss_Z-7 : 0.11366675378642153

loss_Z-8 : 0.09171871159313541

loss_Z-9 : 0.07454095377985544

loss_Z-10 : 0.060863951287728854

loss_Z-11 : 0.04982160753716854

loss_Z-12 : 0.04081462717577101

loss_Z-13 : 0.03342390425594217

loss_Z-14 : 0.02738314558252158

loss_Z-15 : 0.02244436577161384

loss_Z-16 : 0.01838989097022596

loss_Z-17 : 0.015211266646202096

loss_Z-18 : 0.01261882687207233

loss_Z-19 : 0.01031572828722072

loss_Z-20 : 0.008341432683644366

loss_Z-21 : 0.007098270183815285

loss_Z-22 : 0.005682259605182391

loss_Z-23 : 0.004082951854270117

loss_Z-24 : 0.003170357436065522

loss_Z-25 : 0.0024748236481196995

loss_Z-26 : 0.0019218325782615203

loss_Z-27 : 0.001480136026345333

loss_Z-28 : 0.001139301396815596

loss_Z-29 : 0.0008568368309753816

loss_Z-30 : 0.0006478856276950934

loss_Z-31 : 0.00047721743021410327

나의 코드 실행 시간: 1.5002 초
loss : 0.00047721743021410327
Epoch 100, Loss: 0.0259
Adam 학습 코드 실행 시간: 0.1745 초
학습 완료
Validation Loss: 0.0291
Validatio loss in my model : 0.0008534914851742782
data : 5000
loss0 = 0.8108720139386696
loss_Z-0 : 0.4788514192297272

loss_Z-1 : 0.32305011009160756

loss_Z-2 : 0.4266014361606389

it : 2 - learn : 0.037500000000000006
loss_Z-3 : 0.3335082580656919

it : 3 - learn : 0.028125000000000004
loss_Z-4 : 0.30411830770759546

loss_Z-5 : 0.2468645952630471

loss_Z-6 : 0.2013466170905337

loss_Z-7 : 0.16472992473610157

loss_Z-8 : 0.13429998473943056

loss_Z-9 : 0.11072402145918665

loss_Z-10 : 0.09071480074537672

loss_Z-11 : 0.07528331140383855

loss_Z-12 : 0.06355519339787877

loss_Z-13 : 0.05293576454943435

loss_Z-14 : 0.044859537405114405

loss_Z-15 : 0.0386229224727321

loss_Z-16 : 0.03214625985743611

loss_Z-17 : 0.026095823269718293

loss_Z-18 : 0.021223058832686235

loss_Z-19 : 0.01738247037654957

loss_Z-20 : 0.014475271986751739

loss_Z-21 : 0.01206496362089241

loss_Z-22 : 0.009660995099642354

loss_Z-23 : 0.007979134526881934

loss_Z-24 : 0.006581510664445554

loss_Z-25 : 0.005195437525749787

loss_Z-26 : 0.00424930918329458

loss_Z-27 : 0.003633345172880479

loss_Z-28 : 0.0029206583320653943

loss_Z-29 : 0.0023483236530770723

loss_Z-30 : 0.0018863177921286678

loss_Z-31 : 0.0015271397886637485

loss_Z-32 : 0.0012108767505114764

loss_Z-33 : 0.0009639822291620042

loss_Z-34 : 0.0007948787801308799

loss_Z-35 : 0.0006428578333850215

loss_Z-36 : 0.0005261311948755374

나의 코드 실행 시간: 1.7114 초
loss : 0.0005261311948755374
Epoch 100, Loss: 0.0162
Adam 학습 코드 실행 시간: 0.1669 초
학습 완료
Validation Loss: 0.0256
Validatio loss in my model : 0.001928129748558379
data : 5000
loss0 = 1.1096810934505221
loss_Z-0 : 9.776015395099497

it : 0 - learn : 0.037500000000000006
loss_Z-1 : 9.680947028629525

it : 1 - learn : 0.028125000000000004
loss_Z-2 : 9.477273889723632

it : 2 - learn : 0.02109375
loss_Z-3 : 9.0443281450684

it : 3 - learn : 0.015820312500000003
loss_Z-4 : 8.058132496563898

it : 4 - learn : 0.011865234375000002
loss_Z-5 : 6.299250119835347

it : 5 - learn : 0.00889892578125
loss_Z-6 : 4.1851828920104435

it : 6 - learn : 0.0066741943359375005
loss_Z-7 : 2.7355319949208075

it : 7 - learn : 0.005005645751953125
loss_Z-8 : 1.9445261885942628

it : 8 - learn : 0.003754234313964844
loss_Z-9 : 1.5285139712170535

it : 9 - learn : 0.002815675735473633
loss_Z-10 : 1.3136780797129715

it : 10 - learn : 0.0021117568016052247
loss_Z-11 : 1.2039037880850971

it : 11 - learn : 0.0015838176012039186
loss_Z-12 : 1.1484900513432226

it : 12 - learn : 0.001187863200902939
loss_Z-13 : 1.1212520779329105

it : 13 - learn : 0.0008908974006772042
loss_Z-14 : 1.108606772572973

loss_Z-15 : 1.0786879615923768

loss_Z-16 : 1.0509546400649779

loss_Z-17 : 1.0251128428916372

loss_Z-18 : 1.0009462070717063

loss_Z-19 : 0.9782527549571911

loss_Z-20 : 0.9568633234901986

loss_Z-21 : 0.9366842295007315

loss_Z-22 : 0.9175896959837654

loss_Z-23 : 0.8994706446708833

loss_Z-24 : 0.8822340890209412

loss_Z-25 : 0.8601148814642489

loss_Z-26 : 0.8322047210413024

loss_Z-27 : 0.797870711636412

loss_Z-28 : 0.7574989261754592

loss_Z-29 : 0.7095592597339621

loss_Z-30 : 0.6544432199316031

loss_Z-31 : 0.5924020332464104

loss_Z-32 : 0.5246897820438736

loss_Z-33 : 0.4532868670682024

loss_Z-34 : 0.3985653463576802

loss_Z-35 : 0.35071125394228175

loss_Z-36 : 0.3125766798218882

loss_Z-37 : 0.2803069836019571

loss_Z-38 : 0.25252979331290926

loss_Z-39 : 0.22823797144286553

loss_Z-40 : 0.2068954048831128

loss_Z-41 : 0.18828760842616274

loss_Z-42 : 0.16935568354765623

loss_Z-43 : 0.15376046672070173

loss_Z-44 : 0.13949657688235087

loss_Z-45 : 0.1266319186886715

loss_Z-46 : 0.1151259631387964

loss_Z-47 : 0.10422464841535117

loss_Z-48 : 0.0947499090529428

loss_Z-49 : 0.08617423247298696

loss_Z-50 : 0.07842221863544578

loss_Z-51 : 0.07149866776999658

loss_Z-52 : 0.06737727156971102

loss_Z-53 : 0.06122192518287861

loss_Z-54 : 0.05564634235894569

loss_Z-55 : 0.050582547727442875

loss_Z-56 : 0.04597113920918215

loss_Z-57 : 0.04178065115413325

loss_Z-58 : 0.03797115159847027

loss_Z-59 : 0.034501419518941555

loss_Z-60 : 0.03135580079500628

loss_Z-61 : 0.028507869317483954

loss_Z-62 : 0.025933070939924006

loss_Z-63 : 0.023603037124003284

loss_Z-64 : 0.02150041699289724

loss_Z-65 : 0.019633708906732005

loss_Z-66 : 0.018038150017343664

loss_Z-67 : 0.016426470320564705

loss_Z-68 : 0.014951214266567875

loss_Z-69 : 0.013684656161383544

loss_Z-70 : 0.012384139215773284

loss_Z-71 : 0.011287797443927683

loss_Z-72 : 0.010272152118335938

loss_Z-73 : 0.009340859135766462

loss_Z-74 : 0.008397959059050272

나의 코드 실행 시간: 3.5657 초
loss : 0.008397959059050272
Epoch 100, Loss: 0.0270
Adam 학습 코드 실행 시간: 0.1719 초
학습 완료
Validation Loss: 0.0283
Validatio loss in my model : 0.0077431821717463675
data : 5000
